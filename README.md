# üìä SKINFIT - Procesamiento de Datos# SKINFIT - An√°lisis de Datos y Segmentaci√≥n de Clientes



## üöÄ Uso R√°pido## Descripci√≥n del Proyecto



```bashEste proyecto realiza un an√°lisis completo de segmentaci√≥n de clientes para SKINFIT, utilizando datos de sesiones de AgendaPro. El proceso se divide en dos etapas principales:

python RUN.py

```1. **Preprocesamiento y Consolidaci√≥n** (`main.py`)

2. **An√°lisis ML y Segmentaci√≥n** (`analisis_ml.py`)

Este comando ejecuta todo y genera `DatosCompletos.csv` listo para Google Looker.

## Flujo de Trabajo

---

### Paso 1: Preprocesamiento (`main.py`)

## üìÅ Estructura del Proyecto

Este script toma el archivo original de sesiones y realiza:

### **Archivos de Entrada** (originales)

- `Base - Clientes.csv` - Datos de clientes- **Consolidaci√≥n de atributos similares** usando fuzzy matching (umbral 85%)

- `Base - Sesiones.csv` - Datos de sesiones  - Ejemplo: "membresia", "membres√≠a", "membresias" ‚Üí "membresias" (la versi√≥n m√°s frecuente)

- **Filtrado de columnas poco frecuentes** (apariciones < 0.5% del total)

### **Scripts** (numerados por orden de ejecuci√≥n)- **One-hot encoding** de variables categ√≥ricas

1. **`RUN.py`** ‚≠ê - EJECUTAR ESTE (corre todo autom√°ticamente)

2. `1_procesar_sesiones.py` - Procesa y binariza sesiones**Entrada:**

3. `2_procesar_clientes.py` - Agrega columna ID a clientes- `Base2 - Sesiones.csv` (datos originales con ~41,000 sesiones)

4. `3_hacer_join.py` - Une sesiones con clientes

5. `analisis_ml.py` - (Opcional) Segmentaci√≥n de clientes con ML**Salida:**

- `datos_finales_transformados_y_reducidos.csv` (datos consolidados)

### **Archivos de Salida**

- **`DatosCompletos.csv`** ‚≠ê USAR ESTE EN LOOKER**Ejecuci√≥n:**

- `SesionesFinal.csv` (intermedio)```bash

- `ClientesFinal.csv` (intermedio)python main.py

```

---

### Paso 2: An√°lisis ML (`analisis_ml.py`)

## ‚öôÔ∏è ¬øQu√© Hace el Proceso?

Este script toma los datos consolidados y realiza:

### 1Ô∏è‚É£ Procesar Sesiones

- Consolida t√©rminos similares (ej: "membresia" + "membres√≠a" ‚Üí "membresias")- **Agregaci√≥n a nivel de cliente** (de sesiones ‚Üí clientes √∫nicos)

- Convierte listas en columnas binarias (0/1)- **Segmentaci√≥n de clientes** usando K-Means clustering (4 segmentos)

- Crea columnas: `tipo_tratamiento_*`, `productos_*`, `membresia_*`, etc.- **Modelo predictivo** para predecir frecuencia de visitas (Gradient Boosting)

- Agrega columna `ID` para identificar clientes- **Visualizaciones**:

  - Perfiles de segmentos

### 2Ô∏è‚É£ Procesar Clientes  - PCA de segmentos

- Agrega columna `ID` (usa email o nombre_apellido)  - Importancia de variables

- Elimina clientes duplicados  - Predicciones vs reales



### 3Ô∏è‚É£ Hacer JOIN**Entrada:**

- Une sesiones con datos de clientes por columna `ID`- `datos_finales_transformados_y_reducidos.csv`

- Incluye TODOS los clientes (con y sin sesiones)

**Salida:**

---- `output/clientes_segmentados.csv`

- `output/perfiles_segmentos_clientes.png`

## üìä Archivo Final: DatosCompletos.csv- `output/pca_segmentacion_clientes.png`

- `output/importancia_variables_prediccion.png`

### Contenido:- `output/predicciones_vs_reales.png`

- **~43,000 filas** (sesiones + clientes sin sesiones)

- **~70 columnas** binarizadas**Ejecuci√≥n:**

- **~18,000 clientes √∫nicos**```bash

  - 16,000 con sesionespython analisis_ml.py

  - 2,000 sin sesiones```



### Columnas principales:## Ejemplo de Consolidaci√≥n

- `ID` - Identificador √∫nico del cliente

- `fecha` - Fecha en formato ISO (YYYY-MM-DD)El script `main.py` consolida autom√°ticamente variaciones similares:

- `Email`, `Nombres`, `Apellidos` - Datos del cliente

- `tipo_tratamiento_*` - Tratamientos (0/1)### Antes (datos originales):

- `productos_*` - Productos (0/1)```

- `membresia_*` - Membres√≠as (0/1)recomendacion = ["membresia", "membres√≠a", "membresias", "membres√≠as", "membresia_silver"]

- `tipo_piel_*` - Tipos de piel (0/1)```

- `tolerancia_*` - Tolerancia (0/1)

### Despu√©s (consolidado):

---```

recomendacion_membresias  (consolida todas las variaciones de membresia/membres√≠a)

## üîß Ejecutar Scripts Individualesrecomendacion_membresia_silver  (suficientemente diferente, se mantiene separada)

```

Si necesitas ejecutar solo una parte:

## Configuraci√≥n

```bash

# Solo procesar sesiones### Umbral de Similitud (main.py)

python 1_procesar_sesiones.py```python

umbral_similitud = 85  # Porcentaje de similitud para consolidar t√©rminos

# Solo procesar clientes```

python 2_procesar_clientes.py

- **85%**: Captura variaciones como singular/plural, con/sin tildes

# Solo hacer el JOIN (requiere archivos intermedios)- **90%+**: M√°s estricto, solo variaciones muy similares

python 3_hacer_join.py- **80%-**: M√°s permisivo, puede consolidar t√©rminos diferentes



# An√°lisis ML opcional### Umbral de Frecuencia (main.py)

python analisis_ml.py```python

```umbral_frecuencia = 0.005  # 0.5% del total de filas

```

---

- Columnas que aparecen menos veces son descartadas

## üìà Para Google Looker Studio- Con 41,000 sesiones, debe aparecer al menos ~206 veces



1. Sube `DatosCompletos.csv` a Looker### N√∫mero de Segmentos (analisis_ml.py)

2. Configura el tipo de datos:```python

   - `fecha` ‚Üí Fecha (YYYY-MM-DD)n_customer_clusters = 4  # N√∫mero de segmentos de clientes

   - `ID` ‚Üí Texto```

   - Columnas `*_*` ‚Üí N√∫mero (0 o 1)

3. Listo para crear visualizaciones## Estructura de Archivos



### Ejemplos de an√°lisis:```

```sqlSKINFIT/

-- Clientes √∫nicos‚îú‚îÄ‚îÄ main.py                                    # Script de preprocesamiento

COUNT(DISTINCT ID)‚îú‚îÄ‚îÄ analisis_ml.py                             # Script de an√°lisis ML

‚îú‚îÄ‚îÄ Base2 - Sesiones.csv                       # Datos originales

-- Clientes con sesiones‚îú‚îÄ‚îÄ datos_finales_transformados_y_reducidos.csv # Datos consolidados

COUNT(DISTINCT ID) WHERE fecha IS NOT NULL‚îú‚îÄ‚îÄ output/

‚îÇ   ‚îú‚îÄ‚îÄ clientes_segmentados.csv

-- Tratamientos m√°s populares‚îÇ   ‚îú‚îÄ‚îÄ perfiles_segmentos_clientes.png

SUM(tipo_tratamiento_hydra), SUM(tipo_tratamiento_detox), etc.‚îÇ   ‚îú‚îÄ‚îÄ pca_segmentacion_clientes.png

‚îÇ   ‚îú‚îÄ‚îÄ importancia_variables_prediccion.png

-- Productos m√°s recomendados‚îÇ   ‚îî‚îÄ‚îÄ predicciones_vs_reales.png

SUM(productos_retinol), SUM(productos_mascarilla_calmante), etc.‚îî‚îÄ‚îÄ README.md

``````



---## Dependencias



## ‚öôÔ∏è Configuraci√≥n (Opcional)```bash

pip install pandas numpy matplotlib seaborn scikit-learn rapidfuzz openpyxl

Puedes ajustar par√°metros en `1_procesar_sesiones.py`:```



```python## Notas Importantes

umbral_frecuencia = 0.005  # Columnas con <0.5% se descartan

umbral_similitud = 85      # % similitud para fuzzy matching1. **Orden de ejecuci√≥n**: Siempre ejecutar `main.py` primero para generar el archivo consolidado

```2. **Datos originales**: Mantener `Base2 - Sesiones.csv` sin modificar

3. **Consolidaci√≥n**: La funci√≥n `consolidar_atributos()` usa `rapidfuzz` para identificar t√©rminos similares

---4. **Performance**: Con ~8,000 clientes y ~90 caracter√≠sticas, el clustering toma pocos segundos



## üìù Dependencias## Preguntas Frecuentes



```bash### ¬øPor qu√© hay menos clientes que sesiones?

pip install pandas rapidfuzz openpyxl

```Las ~41,000 filas en el archivo original representan **sesiones individuales**. Cada cliente puede tener m√∫ltiples sesiones. Al agrupar por email, obtenemos ~8,000 **clientes √∫nicos**.



Para an√°lisis ML (opcional):Ejemplo:

```bash- `cliente@example.com` tiene 5 sesiones ‚Üí se cuenta como 1 cliente con `num_sesiones=5`

pip install scikit-learn matplotlib seaborn

```### ¬øC√≥mo funciona la consolidaci√≥n?



---El algoritmo usa **fuzzy string matching** para medir la similitud entre t√©rminos:



## üÜò Soluci√≥n de Problemas1. Extrae todos los t√©rminos √∫nicos de una columna

2. Para cada t√©rmino, encuentra otros similares (>85% de similitud)

### Error: "No se encontr√≥ el archivo"3. Agrupa los t√©rminos similares

Verifica que existan:4. Elige el t√©rmino m√°s frecuente como "can√≥nico"

- `Base - Clientes.csv`

- `Base - Sesiones.csv`Ejemplo:

- T√©rminos: ["membresia" (100x), "membres√≠a" (50x), "membresias" (80x)]

### El archivo es muy grande- Similitud: membresia ‚Üî membres√≠a = 89%, membresia ‚Üî membresias = 95%

El script ya optimiza el tama√±o:- Resultado: Todos se consolidan como "membresia" (la m√°s frecuente)

- Solo incluye Email, Nombres, Apellidos de clientes

- Descarta columnas poco frecuentes (<0.5%)### ¬øC√≥mo ajustar el n√∫mero de segmentos?

- Resultado: ~20 MB (manejable para Looker/Sheets)

Edita `analisis_ml.py`:

### Fechas no se ven bien```python

Ya est√°n en formato ISO (YYYY-MM-DD).config = {

En Looker: Campo ‚Üí Tipo ‚Üí Fecha    "n_customer_clusters": 4,  # Cambia este valor

    ...

---}

```

**√öltima actualizaci√≥n:** Octubre 2025  

**Versi√≥n:** 3.0 - SimplificadaPuedes probar con 3, 4, 5, o m√°s segmentos. El valor √≥ptimo depende de tus objetivos de negocio.


## Contacto

Para preguntas o problemas, contactar al equipo de an√°lisis de datos de SKINFIT.
